---
phase: 02-server-quality
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/airflow_unfactor/server.py
  - src/airflow_unfactor/knowledge.py
  - tests/test_server.py
autonomous: true
requirements:
  - SRVR-01
  - SRVR-04

must_haves:
  truths:
    - "Starting the MCP server with missing colin/output directory emits a warning containing 'colin run'"
    - "Starting the MCP server with empty colin/output directory emits a warning containing 'colin run'"
    - "A corrupt JSON file in colin/output logs a warning identifying the filename and error type"
    - "Valid JSON files still load correctly even when a corrupt file is present in the same directory"
  artifacts:
    - path: "src/airflow_unfactor/server.py"
      provides: "Startup warning check in main()"
      contains: "colin/output"
    - path: "src/airflow_unfactor/knowledge.py"
      provides: "Logger warning in load_knowledge() except block"
      contains: "logger.warning"
    - path: "tests/test_server.py"
      provides: "Startup warning tests"
      contains: "TestStartupWarning"
  key_links:
    - from: "src/airflow_unfactor/server.py::main()"
      to: "logging.getLogger"
      via: "warning emission before mcp.run()"
      pattern: "logger.*warning.*colin"
    - from: "src/airflow_unfactor/knowledge.py::load_knowledge()"
      to: "logger.warning"
      via: "except block logging"
      pattern: "logger.warning.*Failed to parse"
---

<objective>
Add startup warnings when Colin output is missing/empty and log warnings when JSON files fail to parse, so operators can diagnose configuration issues without debugging silently broken state.

Purpose: Users who start the MCP server without running `colin run` first get a clear message explaining what to do. Users with corrupt JSON files in colin/output see which file failed and why, instead of silent data loss.

Output: Updated `server.py` with startup check, updated `knowledge.py` with parse error logging, and new `tests/test_server.py` with startup warning tests.
</objective>

<execution_context>
@/Users/gcoyne/.claude/get-shit-done/workflows/execute-plan.md
@/Users/gcoyne/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-server-quality/02-RESEARCH.md
@src/airflow_unfactor/server.py
@src/airflow_unfactor/knowledge.py
@tests/test_knowledge.py

<interfaces>
<!-- Executor needs these existing signatures — no public API changes. -->

From src/airflow_unfactor/server.py:
```python
mcp = FastMCP("airflow-unfactor", instructions="...")

def main() -> None:
    """Run the MCP server over stdio."""
    import sys
    if len(sys.argv) > 1:
        print(f"error: unrecognized arguments: {' '.join(sys.argv[1:])}", file=sys.stderr)
        sys.exit(2)
    mcp.run()
```

From src/airflow_unfactor/knowledge.py:
```python
def load_knowledge(colin_output_dir: str = "colin/output") -> dict[str, Any]:
    # ...
    except (json.JSONDecodeError, KeyError):
        continue  # <-- This is what SRVR-04 changes
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add startup warning in main() and parse error logging in load_knowledge()</name>
  <files>src/airflow_unfactor/server.py, src/airflow_unfactor/knowledge.py</files>
  <action>
Two files, two changes:

**1. In `src/airflow_unfactor/server.py` — add SRVR-01 startup warning in `main()`:**

After the `sys.argv` check and before `mcp.run()`, add a check for missing/empty Colin output:

```python
import logging
from pathlib import Path

colin_dir = Path("colin/output")
if not colin_dir.exists() or not list(colin_dir.glob("*.json")):
    logging.getLogger("airflow_unfactor").warning(
        "Colin output directory missing or empty (%s). "
        "Run `colin run` to compile translation knowledge. "
        "Falling back to built-in operator mappings.",
        colin_dir,
    )
```

Place this AFTER the `sys.argv` guard and BEFORE `mcp.run()`. The `import logging` and `from pathlib import Path` can go at the top of `main()` alongside the existing `import sys`, or at module level — either is fine since `main()` already lazily imports `sys`.

**IMPORTANT**: Do NOT put this check in `load_knowledge()` or at module import time. It must be in `main()` only, so it doesn't fire during tests.

**2. In `src/airflow_unfactor/knowledge.py` — add SRVR-04 parse error logging:**

Add `import logging` and `logger = logging.getLogger(__name__)` at module level (after existing imports, before `FALLBACK_KNOWLEDGE`).

Replace the bare `except (json.JSONDecodeError, KeyError): continue` in `load_knowledge()` (line 135-136) with:

```python
except (json.JSONDecodeError, KeyError) as e:
    logger.warning(
        "Failed to parse %s: %s: %s",
        json_file.name, type(e).__name__, e
    )
    continue
```

This logs the filename, error type, and error message — enough for operators to diagnose corrupt or hand-edited JSON. The `continue` ensures other files still load.
  </action>
  <verify>
    <automated>cd /Users/gcoyne/src/prefect/airflow-unfactor && uv run python -c "
import logging, json
from pathlib import Path
from airflow_unfactor.knowledge import load_knowledge
logging.basicConfig(level=logging.WARNING)
# Test SRVR-04: create a temp dir with bad JSON
import tempfile, os
d = tempfile.mkdtemp()
Path(d, 'bad.json').write_text('NOT JSON')
Path(d, 'good.json').write_text(json.dumps({'X': {'t': 1}}))
r = load_knowledge(d)
assert 'X' in r, 'Good file not loaded after bad file'
print('SRVR-04 OK: bad JSON logged, good file loaded')
"</automated>
  </verify>
  <done>
    - `main()` emits a WARNING-level log when colin/output is missing or contains no .json files
    - `load_knowledge()` logs `"Failed to parse {filename}: {ErrorType}: {message}"` for each unparseable file
    - `load_knowledge()` continues loading remaining valid files after a bad one
  </done>
</task>

<task type="auto">
  <name>Task 2: Create tests/test_server.py with startup warning tests and extend test_knowledge.py for parse error logging</name>
  <files>tests/test_server.py, tests/test_knowledge.py</files>
  <action>
**1. Create `tests/test_server.py`** — new file with `TestStartupWarning` class:

```python
"""Tests for server startup behavior."""

import logging
from unittest.mock import patch

from airflow_unfactor.server import main


class TestStartupWarning:
    """Tests for SRVR-01: startup warning when Colin output missing/empty."""

    def test_warns_when_colin_dir_missing(self, tmp_path, caplog):
        """Warning emitted when colin/output directory does not exist."""
        with caplog.at_level(logging.WARNING, logger="airflow_unfactor"):
            with patch("airflow_unfactor.server.mcp") as mock_mcp:
                with patch("airflow_unfactor.server.Path") as mock_path_cls:
                    mock_path = mock_path_cls.return_value
                    mock_path.exists.return_value = False
                    mock_mcp.run.return_value = None
                    main()
        assert "colin run" in caplog.text.lower() or "colin run" in caplog.text

    def test_warns_when_colin_dir_empty(self, tmp_path, caplog):
        """Warning emitted when colin/output exists but has no JSON files."""
        colin_dir = tmp_path / "colin" / "output"
        colin_dir.mkdir(parents=True)
        with caplog.at_level(logging.WARNING, logger="airflow_unfactor"):
            with patch("airflow_unfactor.server.mcp") as mock_mcp:
                with patch("airflow_unfactor.server.Path", return_value=colin_dir):
                    mock_mcp.run.return_value = None
                    main()
        assert "colin run" in caplog.text.lower() or "colin run" in caplog.text

    def test_no_warning_when_colin_dir_has_json(self, tmp_path, caplog):
        """No warning when colin/output has JSON files."""
        colin_dir = tmp_path / "colin" / "output"
        colin_dir.mkdir(parents=True)
        (colin_dir / "test.json").write_text("{}")
        with caplog.at_level(logging.WARNING, logger="airflow_unfactor"):
            with patch("airflow_unfactor.server.mcp") as mock_mcp:
                with patch("airflow_unfactor.server.Path", return_value=colin_dir):
                    mock_mcp.run.return_value = None
                    main()
        assert "colin run" not in caplog.text.lower()
```

NOTE to executor: The exact mocking strategy depends on how `main()` references `Path`. If `main()` uses `from pathlib import Path` locally, mock accordingly. The key behavior: `main()` checks `Path("colin/output").exists()` and `list(path.glob("*.json"))`. The tests must verify the WARNING is emitted with "colin run" in the message. Adjust mocking to match actual implementation — the test intent matters more than the exact mock structure.

**2. Add `TestParseErrorLogging` class to `tests/test_knowledge.py`:**

```python
class TestParseErrorLogging:
    """Tests for SRVR-04: logging when JSON files fail to parse."""

    def test_logs_warning_for_invalid_json(self, tmp_path, caplog):
        """Invalid JSON file triggers a warning with filename."""
        (tmp_path / "bad.json").write_text("not json {{{")
        (tmp_path / "good.json").write_text(json.dumps({"X": {"type": "ok"}}))
        with caplog.at_level(logging.WARNING):
            result = load_knowledge(str(tmp_path))
        assert "bad.json" in caplog.text
        assert "JSONDecodeError" in caplog.text
        assert "X" in result  # good file still loaded

    def test_logs_warning_includes_error_type(self, tmp_path, caplog):
        """Warning message includes the error type name."""
        (tmp_path / "corrupt.json").write_text('{"entries": [{"no_name": true}]}')
        # This may or may not trigger KeyError depending on implementation
        # At minimum, test that invalid JSON format is caught
        (tmp_path / "broken.json").write_text("[1, 2, 3")
        with caplog.at_level(logging.WARNING):
            load_knowledge(str(tmp_path))
        # At least the broken JSON should be logged
        if "broken.json" in caplog.text:
            assert "JSONDecodeError" in caplog.text
```

Add `import logging` to the test file imports if not already present.
  </action>
  <verify>
    <automated>cd /Users/gcoyne/src/prefect/airflow-unfactor && uv run pytest tests/test_server.py tests/test_knowledge.py::TestParseErrorLogging -x -v 2>&1 | tail -20</automated>
  </verify>
  <done>
    - `tests/test_server.py` exists with 3 passing tests for startup warning
    - `TestParseErrorLogging` passes with assertions on filename and error type in log output
    - Full suite green: `uv run pytest` exits 0
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_server.py -x -v` — startup warning tests pass
2. `uv run pytest tests/test_knowledge.py::TestParseErrorLogging -x -v` — parse error logging tests pass
3. `uv run pytest` — full suite green (66+ tests, no regressions)
4. Manual smoke test: `cd /tmp && uv run --directory /path/to/project python -c "from airflow_unfactor.server import main"` — no import-time warnings (warning only fires from `main()`)
</verification>

<success_criteria>
- SRVR-01: Starting MCP server with missing/empty colin/output emits WARNING containing "colin run" — verified by test_server.py
- SRVR-04: Corrupt JSON file in colin/output causes a WARNING log with filename and error type — verified by TestParseErrorLogging
- SRVR-04: Valid files continue loading after a corrupt file — verified by assertion in test
- No warning emitted at import time or during unrelated tests
- Zero test regressions across full suite
</success_criteria>

<output>
After completion, create `.planning/phases/02-server-quality/02-02-SUMMARY.md`
</output>
